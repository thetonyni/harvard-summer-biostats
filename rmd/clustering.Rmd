---
title: "Clustering"
author: "Tony Ni, Antonella Basso, Jose Lopez"
date: "6/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, include = FALSE}
library(mosaic) 
library(cluster) #for access to daisy function
library(lattice)
library(flexclust)
library(dplyr)
library(ggplot2)
library(readr)
library(Rtsne)
```

## Reading in Data

```{r}
setwd("~/harvard-summer-biostats")
df <- read_csv("data/wide_illinois.csv") #read in data
df1 <- na.omit(df) #get rid of na's
```

## Hierarchical Methods

If we want to look for cereal groups via hierarchical clustering, we need to construct a distance matrix. Distances are constructed with the *dist* function, and we need to choose whether we compute them on scaled or unscaled variables (standardize or not). 

```{r}
df.dist <- dist(df1[, -c(1:5)])
```

Now we look at how hierarchical clustering is applied. The relevant function is *hclust*. 

```{r}
hcsingle <- hclust(df.dist, method = "single") 
list(hcsingle) # reminds you of properties of the solution, if desired
```

This creates the solution, and we can look at the dendrogram as:

```{r}
plot(hcsingle)
```

The options for hclust in terms of linkages are provided in the help under options for method. The following options are listed: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median" or "centroid".

In order to obtain cluster labels, we need to *cut* our dendrograms.

```{r}
singleSol <- (cutree(hcsingle, k = 3)) #cluster labels are numeric, k= # clusters
summary(as.factor(singleSol)) #as factor to get table
```

To learn more details about the clusters we found:

```{r}
hcward <- hclust(df.dist, method = "ward.D") 
plot(hcward, labels = df1$gradient, cex = 0.7) #cex adjusts size of label

wardSol <- (cutree(hcward, k = 2)) #cluster labels are numeric, k= # clusters
summary(as.factor(wardSol)) #as factor to get table

favstats(Antimony ~ wardSol, data = df1) #can choose any variable
bwplot(Antimony ~ as.factor(wardSol), data = df1)
```

Our cluster sizes are extremely uneven... Our first clsuter has 172 wells and the second has 19.

```{r}x
favstats(#chemical here ~ wardSol, data = df1) 
bwplot(#chemical here ~ as.factor(wardSol), data = df1)
```

We can view the solution in the PC space (say 2-D) to see how well-separated the clusters are in that space. Because we used an unstandardized distance, we will run the PCA on the covariance matrix.

```{r}
dfPCA <- princomp(df1[, -c(1:5)], cor = FALSE)

plot(dfPCA$scores[, 1:2], type = "n", xlab = "PC1", ylab = "PC2", main = "Ward's cluster solution") #blank!
text(dfPCA$scores[, 1:2], labels = wardSol, cex = 0.6) #add the text
```

We may want to go into investigation to see what sort of traits/attributes are shared by the wells in each cluster and seeing if we can find meaning in them.

## K-means Methods

For k-means, we don't need to compute the distance matrix ourselves. We feed the function the data set to operate on:

```{r}
Ksol1 <- kmeans(scale(df1[, -c(1:5)]), centers = 2) #centers is the # of clusters desired
list(Ksol1) #so you can see what it gives you
```

The list option provides us with lots of information. We can pull out the cluster means as:

```{r}
Ksol1$centers
```

In order to determine if we have chosen a "good" value of the number of clusters, we can look at the within cluster sum of squares for this solution and a few other options for k, the number of clusters. This runs the solution from 1 to 10 clusters and pulls the within group sum of squares from each. 

```{r}
n <- nrow(df1) #number of observations

wss <- rep(0, 10) #creates 10 copies of 0 to create an empty vector
for(i in 1:10){
  wss[i] <- sum(kmeans(scale(df1[, -c(1:5)]), centers = i)$withinss)
} 

plot(1:10, wss, type = "b", xlab = "Number of groups", ylab = "Within groups sum of squares")
```

We look for elbows in the plot - here there are elbows at 2 and 6 (ish?), maybe these values will be good to use? 

With two clusters, we should see if there is any relationship with sites...

```{r}
tally(Ksol1$cluster ~ type, data = df1, format = "count")
```

There does seem to be something of interest here... The first cluster has a varied mix between all types with the majority in SI, while wells in cluster 2 seem to only consist of L.

We can compare clustering solutions with similar tables. How do the K-means and Ward's solutions overlap?

```{r}
tally(Ksol1$cluster ~ wardSol, data = df1, format = "count")
```

They seem to match up fairly well!




